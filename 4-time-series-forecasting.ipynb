{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cleaned_structured_data.csv\", sep = \";\")\n",
    "data = data.set_index([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45176cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine learning\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"id\"] = data.reset_index()[\"id\"].unique()\n",
    "dataset = dataset.set_index(\"id\")\n",
    "for i in range(107):\n",
    "    dataset[\"ADM\" + str(i)] = data[data[\"day\"] == i][\"ADM\"]\n",
    "    dataset[\"o2Saturation\" + str(i)] = data[data[\"day\"] == i][\"o2Saturation\"]\n",
    "    dataset[\"temperature\" + str(i)] = data[data[\"day\"] == i][\"temperature\"]\n",
    "    dataset[\"bloodPressure\" + str(i)] = data[data[\"day\"] == i][\"bloodPressure\"]\n",
    "    dataset[\"ADM\" + str(i)] = data[data[\"day\"] == i][\"ADM\"]\n",
    "dataset[\"age\"] = data.groupby(\"id\").first()[\"age\"]\n",
    "dataset[\"gender\"] = data.groupby(\"id\").first()[\"gender\"]\n",
    "dataset[\"BMI\"] = data.groupby(\"id\").mean()[\"BMI\"]\n",
    "dataset[\"gender\"] = np.where(dataset[\"gender\"] == \"Man\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44dfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for traditional time series forecasting\n",
    "\n",
    "structured_data = data[data[\"daysOfHospital\"] >= 10].reset_index()\n",
    "structured_data = structured_data[structured_data[\"BMI\"] > 31]\n",
    "id_list = structured_data[structured_data[\"daysOfHospital\"] >= 10][\"id\"].drop_duplicates()\n",
    "time_series_set = [[] for i in range(100)]\n",
    "for id in id_list:\n",
    "    data = structured_data[structured_data[\"id\"] == id].reset_index()\n",
    "    for i in range(10, len(data) + 1):\n",
    "        time_series_set[i-10].append(data[:i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c3d20",
   "metadata": {},
   "source": [
    "# forecast temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de03f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forecast temperature: traditional methods\n",
    "\n",
    "mse_avg_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_naive_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_ets_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_movingavg_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_arima_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_arima2_TEMPERATURE = [[] for i in range(100)]\n",
    "mse_arima3_TEMPERATURE = [[] for i in range(100)]\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"temperature\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "\n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_TEMPERATURE[i].append(mean_squared_error(data[-3:], y_hat_8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata_temperature(i):\n",
    "    train_data = dataset[dataset[\"temperature\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"temperature\" + str(i + 6), \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"temperature\" + str(i + 3), \"temperature\" + str(i + 2), \"temperature\" + str(i + 1), \"temperature\" + str(i)]]\n",
    "    train_data.columns = ['temperature6', 'temperature5', 'temperature4', 'temperature3', 'temperature2', 'temperature1', 'temperature0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0_temperature(i):\n",
    "    train_data = dataset[dataset[\"temperature\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"temperature\" + str(i + 6), \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"temperature\" + str(i + 3), \"temperature\" + str(i + 2), \"temperature\" + str(i + 1), \"temperature\" + str(i)]]\n",
    "    train_data.columns = ['temperature6', 'temperature5', 'temperature4', 'temperature3', 'temperature2', 'temperature1', 'temperature0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata_temperature(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"temperature\" + str(j)] = test_data[\"temperature\" + str(j + 1)]\n",
    "    test_data[\"temperature5\"] = y\n",
    "    test_data[\"temperature6\"] = dataset[\"temperature\" + str(i + 6)]\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast temperature: lightgbm\n",
    "\n",
    "mse_temperature = []\n",
    "y_list_temperature = []\n",
    "y_hat_list_temperature = []\n",
    "mse_list_temperature = pd.Series()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "         }\n",
    "\n",
    "for i in range(100):\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "\n",
    "    x = train_data_temperature.iloc[:,1:]\n",
    "    y = train_data_temperature.iloc[:,0]\n",
    "\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "\n",
    "    test_data1 = build_testdata0_temperature(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "\n",
    "    test_data2 = build_testdata_temperature(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_temperature(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_temperature.extend(list(y1))\n",
    "    y_list_temperature.extend(list(y2))\n",
    "    y_list_temperature.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_temperature.extend(list(y1_hat))\n",
    "    y_hat_list_temperature.extend(list(y2_hat))\n",
    "    y_hat_list_temperature.extend(list(y3_hat))\n",
    "    \n",
    "    \n",
    "    mse_list_temperature = mse_list_temperature.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_temperature.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d35f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast temperature: xgboost\n",
    "\n",
    "mse_xgboost_temperature = []\n",
    "y_list_xgboost_temperature = []\n",
    "y_hat_list_xgboost_temperature = []\n",
    "train_data_xgboost_temperature = pd.DataFrame()\n",
    "mse_list_xgboost_temperature = pd.Series()\n",
    "\n",
    "params = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "    }\n",
    "\n",
    "for i in range(97):\n",
    "    train_data_xgboost_temperature = train_data_xgboost_temperature.append(build_traindata_temperature(i))\n",
    "\n",
    "    x = train_data_xgboost_temperature.iloc[:,1:]\n",
    "    y = train_data_xgboost_temperature.iloc[:,0]\n",
    "    \n",
    "    model=xgb.XGBRegressor(**params)\n",
    "    model.fit(x, y)\n",
    "\n",
    "\n",
    "    test_data1 = build_testdata0_temperature(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    test_data2 = build_testdata_temperature(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_temperature(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_xgboost_temperature.extend(list(y1))\n",
    "    y_list_xgboost_temperature.extend(list(y2))\n",
    "    y_list_xgboost_temperature.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_xgboost_temperature.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost_temperature.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost_temperature.extend(list(y3_hat))\n",
    "    \n",
    "    mse_list_xgboost_temperature = mse_list_xgboost_temperature.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_xgboost_temperature.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966961d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sum(i) for i in mse_avg_TEMPERATURE)/sum(len(i) for i in mse_avg_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_naive_TEMPERATURE)/sum(len(i) for i in mse_naive_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_ets_TEMPERATURE)/sum(len(i) for i in mse_ets_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_movingavg_TEMPERATURE)/sum(len(i) for i in mse_movingavg_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_arima_TEMPERATURE)/sum(len(i) for i in mse_arima_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_arima2_TEMPERATURE)/sum(len(i) for i in mse_arima2_TEMPERATURE))\n",
    "print(sum(sum(i) for i in mse_arima3_TEMPERATURE)/sum(len(i) for i in mse_arima3_TEMPERATURE))\n",
    "print(mean_squared_error(y_list_temperature, y_hat_list_temperature))\n",
    "print(mean_squared_error(y_list_xgboost_temperature,y_hat_list_xgboost_temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208012a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.37 * 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sum(sum(i) for i in mse_avg_TEMPERATURE)/sum(len(i) for i in mse_avg_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_naive_TEMPERATURE)/sum(len(i) for i in mse_naive_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_ets_TEMPERATURE)/sum(len(i) for i in mse_ets_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_movingavg_TEMPERATURE)/sum(len(i) for i in mse_movingavg_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_arima_TEMPERATURE)/sum(len(i) for i in mse_arima_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_arima2_TEMPERATURE)/sum(len(i) for i in mse_arima2_TEMPERATURE)) ** (1/2) )\n",
    "print((sum(sum(i) for i in mse_arima3_TEMPERATURE)/sum(len(i) for i in mse_arima3_TEMPERATURE)) ** (1/2) )\n",
    "print((mean_squared_error(y_list_temperature, y_hat_list_temperature)) ** (1/2) )\n",
    "print((mean_squared_error(y_list_xgboost_temperature,y_hat_list_xgboost_temperature)) ** (1/2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648c817",
   "metadata": {},
   "source": [
    "# forecast blood pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5013dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast blood pressure: traditional methods\n",
    "\n",
    "# forecast blood pressure: traditional methods\n",
    "\n",
    "mse_avg_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_naive_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_ets_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_movingavg_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_arima_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_arima2_BLOODPRESSURE = [[] for i in range(100)]\n",
    "mse_arima3_BLOODPRESSURE = [[] for i in range(100)]\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"bloodPressure\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "\n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_BLOODPRESSURE[i].append(mean_squared_error(data[-3:], y_hat_8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata_bloodPressure(i):\n",
    "    train_data = dataset[dataset[\"bloodPressure\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"bloodPressure\" + str(i + 6), \"bloodPressure\" + str(i + 5), \"bloodPressure\" + str(i + 4), \"bloodPressure\" + str(i + 3), \"bloodPressure\" + str(i + 2), \"bloodPressure\" + str(i + 1), \"bloodPressure\" + str(i)]]\n",
    "    train_data.columns = ['bloodPressure6', 'bloodPressure5', 'bloodPressure4', 'bloodPressure3', 'bloodPressure2', 'bloodPressure1', 'bloodPressure0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0_bloodPressure(i):\n",
    "    train_data = dataset[dataset[\"bloodPressure\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"bloodPressure\" + str(i + 6), \"bloodPressure\" + str(i + 5), \"bloodPressure\" + str(i + 4), \"bloodPressure\" + str(i + 3), \"bloodPressure\" + str(i + 2), \"bloodPressure\" + str(i + 1), \"bloodPressure\" + str(i)]]\n",
    "    train_data.columns = ['bloodPressure6', 'bloodPressure5', 'bloodPressure4', 'bloodPressure3', 'bloodPressure2', 'bloodPressure1', 'bloodPressure0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata_bloodPressure(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"bloodPressure\" + str(j)] = test_data[\"bloodPressure\" + str(j + 1)]\n",
    "    test_data[\"bloodPressure5\"] = y\n",
    "    test_data[\"bloodPressure6\"] = dataset[\"bloodPressure\" + str(i + 6)]\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast bloodPressure: lightgbm\n",
    "\n",
    "mse_bloodPressure = []\n",
    "y_list_bloodPressure = []\n",
    "y_hat_list_bloodPressure = []\n",
    "mse_list_bloodPressure = pd.Series()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "         }\n",
    "\n",
    "for i in range(100):\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "\n",
    "    x = train_data_bloodPressure.iloc[:,1:]\n",
    "    y = train_data_bloodPressure.iloc[:,0]\n",
    "\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "\n",
    "    test_data1 = build_testdata0_bloodPressure(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "\n",
    "    test_data2 = build_testdata_bloodPressure(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_bloodPressure(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_bloodPressure.extend(list(y1))\n",
    "    y_list_bloodPressure.extend(list(y2))\n",
    "    y_list_bloodPressure.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_bloodPressure.extend(list(y1_hat))\n",
    "    y_hat_list_bloodPressure.extend(list(y2_hat))\n",
    "    y_hat_list_bloodPressure.extend(list(y3_hat))\n",
    "    \n",
    "    \n",
    "    mse_list_bloodPressure = mse_list_bloodPressure.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_bloodPressure.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast bloodPressure: xgboost\n",
    "\n",
    "mse_xgboost_bloodPressure = []\n",
    "y_list_xgboost_bloodPressure = []\n",
    "y_hat_list_xgboost_bloodPressure = []\n",
    "train_data_xgboost_bloodPressure = pd.DataFrame()\n",
    "mse_list_xgboost_bloodPressure = pd.Series()\n",
    "\n",
    "params = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "    }\n",
    "\n",
    "for i in range(97):\n",
    "    train_data_xgboost_bloodPressure = train_data_xgboost_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "\n",
    "    x = train_data_xgboost_bloodPressure.iloc[:,1:]\n",
    "    y = train_data_xgboost_bloodPressure.iloc[:,0]\n",
    "    \n",
    "    model=xgb.XGBRegressor(**params)\n",
    "    model.fit(x, y)\n",
    "\n",
    "\n",
    "    test_data1 = build_testdata0_bloodPressure(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    test_data2 = build_testdata_bloodPressure(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_bloodPressure(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_xgboost_bloodPressure.extend(list(y1))\n",
    "    y_list_xgboost_bloodPressure.extend(list(y2))\n",
    "    y_list_xgboost_bloodPressure.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_xgboost_bloodPressure.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost_bloodPressure.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost_bloodPressure.extend(list(y3_hat))\n",
    "    \n",
    "    mse_list_xgboost_bloodPressure = mse_list_xgboost_bloodPressure.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_xgboost_bloodPressure.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sum(i) for i in mse_avg_BLOODPRESSURE)/sum(len(i) for i in mse_avg_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_naive_BLOODPRESSURE)/sum(len(i) for i in mse_naive_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_ets_BLOODPRESSURE)/sum(len(i) for i in mse_ets_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_movingavg_BLOODPRESSURE)/sum(len(i) for i in mse_movingavg_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_arima_BLOODPRESSURE)/sum(len(i) for i in mse_arima_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_arima2_BLOODPRESSURE)/sum(len(i) for i in mse_arima2_BLOODPRESSURE))\n",
    "print(sum(sum(i) for i in mse_arima3_BLOODPRESSURE)/sum(len(i) for i in mse_arima3_BLOODPRESSURE))\n",
    "print(mean_squared_error(y_list_bloodPressure, y_hat_list_bloodPressure))\n",
    "print(mean_squared_error(y_list_xgboost_bloodPressure,y_hat_list_xgboost_bloodPressure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sum(sum(i) for i in mse_avg_BLOODPRESSURE)/sum(len(i) for i in mse_avg_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_naive_BLOODPRESSURE)/sum(len(i) for i in mse_naive_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_ets_BLOODPRESSURE)/sum(len(i) for i in mse_ets_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_movingavg_BLOODPRESSURE)/sum(len(i) for i in mse_movingavg_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima_BLOODPRESSURE)/sum(len(i) for i in mse_arima_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima2_BLOODPRESSURE)/sum(len(i) for i in mse_arima2_BLOODPRESSURE)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima3_BLOODPRESSURE)/sum(len(i) for i in mse_arima3_BLOODPRESSURE)) ** (1/2))\n",
    "print((mean_squared_error(y_list_bloodPressure, y_hat_list_bloodPressure)) ** (1/2))\n",
    "print((mean_squared_error(y_list_xgboost_bloodPressure,y_hat_list_xgboost_bloodPressure)) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84a710",
   "metadata": {},
   "source": [
    "# forecast o2saturation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast blood pressure: traditional methods\n",
    "\n",
    "# forecast blood pressure: traditional methods\n",
    "\n",
    "mse_avg_O2SATURATION = [[] for i in range(100)]\n",
    "mse_naive_O2SATURATION = [[] for i in range(100)]\n",
    "mse_ets_O2SATURATION = [[] for i in range(100)]\n",
    "mse_movingavg_O2SATURATION = [[] for i in range(100)]\n",
    "mse_arima_O2SATURATION = [[] for i in range(100)]\n",
    "mse_arima2_O2SATURATION = [[] for i in range(100)]\n",
    "mse_arima3_O2SATURATION = [[] for i in range(100)]\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"o2Saturation\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "\n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_O2SATURATION[i].append(mean_squared_error(data[-3:], y_hat_8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata_o2Saturation(i):\n",
    "    train_data = dataset[dataset[\"o2Saturation\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"o2Saturation\" + str(i + 6), \"o2Saturation\" + str(i + 5), \"o2Saturation\" + str(i + 4), \"o2Saturation\" + str(i + 3), \"o2Saturation\" + str(i + 2), \"o2Saturation\" + str(i + 1), \"o2Saturation\" + str(i)]]\n",
    "    train_data.columns = ['o2Saturation6', 'o2Saturation5', 'o2Saturation4', 'o2Saturation3', 'o2Saturation2', 'o2Saturation1', 'o2Saturation0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0_o2Saturation(i):\n",
    "    train_data = dataset[dataset[\"o2Saturation\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"o2Saturation\" + str(i + 6), \"o2Saturation\" + str(i + 5), \"o2Saturation\" + str(i + 4), \"o2Saturation\" + str(i + 3), \"o2Saturation\" + str(i + 2), \"o2Saturation\" + str(i + 1), \"o2Saturation\" + str(i)]]\n",
    "    train_data.columns = ['o2Saturation6', 'o2Saturation5', 'o2Saturation4', 'o2Saturation3', 'o2Saturation2', 'o2Saturation1', 'o2Saturation0']\n",
    "    return train_data\n",
    "\n",
    "def build_testdata_o2Saturation(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"o2Saturation\" + str(j)] = test_data[\"o2Saturation\" + str(j + 1)]\n",
    "    test_data[\"o2Saturation5\"] = y\n",
    "    test_data[\"o2Saturation6\"] = dataset[\"o2Saturation\" + str(i + 6)]\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast o2Saturation: lightgbm\n",
    "\n",
    "mse_o2Saturation = []\n",
    "y_list_o2Saturation = []\n",
    "y_hat_list_o2Saturation = []\n",
    "mse_list_o2Saturation = pd.Series()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "         }\n",
    "\n",
    "for i in range(100):\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "\n",
    "    x = train_data_o2Saturation.iloc[:,1:]\n",
    "    y = train_data_o2Saturation.iloc[:,0]\n",
    "\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "\n",
    "    test_data1 = build_testdata0_o2Saturation(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "\n",
    "    test_data2 = build_testdata_o2Saturation(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_o2Saturation(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_o2Saturation.extend(list(y1))\n",
    "    y_list_o2Saturation.extend(list(y2))\n",
    "    y_list_o2Saturation.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_o2Saturation.extend(list(y1_hat))\n",
    "    y_hat_list_o2Saturation.extend(list(y2_hat))\n",
    "    y_hat_list_o2Saturation.extend(list(y3_hat))\n",
    "    \n",
    "    \n",
    "    mse_list_o2Saturation = mse_list_o2Saturation.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_o2Saturation.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast o2Saturation: xgboost\n",
    "\n",
    "mse_xgboost_o2Saturation = []\n",
    "y_list_xgboost_o2Saturation = []\n",
    "y_hat_list_xgboost_o2Saturation = []\n",
    "train_data_xgboost_o2Saturation = pd.DataFrame()\n",
    "mse_list_xgboost_o2Saturation = pd.Series()\n",
    "\n",
    "params = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "    }\n",
    "\n",
    "for i in range(97):\n",
    "    train_data_xgboost_o2Saturation = train_data_xgboost_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "\n",
    "    x = train_data_xgboost_o2Saturation.iloc[:,1:]\n",
    "    y = train_data_xgboost_o2Saturation.iloc[:,0]\n",
    "    \n",
    "    model=xgb.XGBRegressor(**params)\n",
    "    model.fit(x, y)\n",
    "\n",
    "\n",
    "    test_data1 = build_testdata0_o2Saturation(i+1)\n",
    "    x1 = test_data1.iloc[:,1:]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    test_data2 = build_testdata_o2Saturation(test_data1, y1_hat, i+2)\n",
    "    x2 = test_data2.iloc[:,1:]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    test_data3 = build_testdata_o2Saturation(test_data2, y2_hat, i+3)\n",
    "    x3 = test_data3.iloc[:,1:]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list_xgboost_o2Saturation.extend(list(y1))\n",
    "    y_list_xgboost_o2Saturation.extend(list(y2))\n",
    "    y_list_xgboost_o2Saturation.extend(list(y3))\n",
    "    \n",
    "    y_hat_list_xgboost_o2Saturation.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost_o2Saturation.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost_o2Saturation.extend(list(y3_hat))\n",
    "    \n",
    "    mse_list_xgboost_o2Saturation = mse_list_xgboost_o2Saturation.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse_xgboost_o2Saturation.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b22b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sum(i) for i in mse_avg_O2SATURATION)/sum(len(i) for i in mse_avg_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_naive_O2SATURATION)/sum(len(i) for i in mse_naive_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_ets_O2SATURATION)/sum(len(i) for i in mse_ets_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_movingavg_O2SATURATION)/sum(len(i) for i in mse_movingavg_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_arima_O2SATURATION)/sum(len(i) for i in mse_arima_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_arima2_O2SATURATION)/sum(len(i) for i in mse_arima2_O2SATURATION))\n",
    "print(sum(sum(i) for i in mse_arima3_O2SATURATION)/sum(len(i) for i in mse_arima3_O2SATURATION))\n",
    "print(mean_squared_error(y_list_o2Saturation, y_hat_list_o2Saturation))\n",
    "print(mean_squared_error(y_list_xgboost_o2Saturation,y_hat_list_xgboost_o2Saturation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sum(sum(i) for i in mse_avg_O2SATURATION)/sum(len(i) for i in mse_avg_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_naive_O2SATURATION)/sum(len(i) for i in mse_naive_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_ets_O2SATURATION)/sum(len(i) for i in mse_ets_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_movingavg_O2SATURATION)/sum(len(i) for i in mse_movingavg_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima_O2SATURATION)/sum(len(i) for i in mse_arima_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima2_O2SATURATION)/sum(len(i) for i in mse_arima2_O2SATURATION)) ** (1/2))\n",
    "print((sum(sum(i) for i in mse_arima3_O2SATURATION)/sum(len(i) for i in mse_arima3_O2SATURATION)) ** (1/2))\n",
    "print((mean_squared_error(y_list_o2Saturation, y_hat_list_o2Saturation)) ** (1/2))\n",
    "print((mean_squared_error(y_list_xgboost_o2Saturation,y_hat_list_xgboost_o2Saturation)) ** (1/2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dae3c7",
   "metadata": {},
   "source": [
    "# forecast ADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ed5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(_y1, _y1_) ** (1/2))\n",
    "print(mean_squared_error(_y2, _y2_) ** (1/2))\n",
    "print(mean_squared_error(_y3, _y3_) ** (1/2))\n",
    "print(mean_squared_error(_y3 + _y2 + _y1, _y3_ + _y2_ + _y1_) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9609b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"naive\":[sum(x)/len(x) for x in mse_naive_ADM[:50]]\n",
    "                  ,\"mean\":[sum(x)/len(x) for x in mse_avg_ADM[:50]]\n",
    "                  ,\"exponential smoothing\":[sum(x)/len(x) for x in mse_ets_ADM[:50]]\n",
    "                  ,\"ARIMA(1,1,1)\":[sum(x)/len(x) for x in mse_arima_ADM[:50]]\n",
    "                  ,\"ARIMA(0,1,1)\":[sum(x)/len(x) for x in mse_arima2_ADM[:50]]\n",
    "                  ,\"ARIMA(1,1,0)\":[sum(x)/len(x) for x in mse_arima3_ADM[:50]]\n",
    "                  ,\"Light GBM\": mse[:50]\n",
    "                  ,\"Xgboost\": mse_xgboost[:50]})\n",
    "a.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81649ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# traditional \n",
    "\n",
    "mse_avg_ADM = [[] for i in range(100)]\n",
    "mse_naive_ADM = [[] for i in range(100)]\n",
    "mse_ets_ADM = [[] for i in range(100)]\n",
    "mse_movingavg_ADM = [[] for i in range(100)]\n",
    "mse_arima_ADM = [[] for i in range(100)]\n",
    "mse_arima2_ADM = [[] for i in range(100)]\n",
    "mse_arima3_ADM = [[] for i in range(100)]\n",
    "\n",
    "y1 = []\n",
    "y1_ = []\n",
    "y2 = []\n",
    "y2_ = []\n",
    "y3 = []\n",
    "y3_ = []\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"ADM\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_ADM[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_ADM[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "        \n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_ADM[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_ADM[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_ADM[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_ADM[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "\n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_ADM[i].append(mean_squared_error(data[-3:], y_hat_8))\n",
    "        \n",
    "        y1.append(data.values[-3])\n",
    "        y1_.append(y_hat_8.values[-3])\n",
    "        y2.append(data.values[-2])\n",
    "        y2_.append(y_hat_8.values[-2])\n",
    "        y3.append(data.values[-1])\n",
    "        y3_.append(y_hat_8.values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata(i):\n",
    "    train_data = dataset[dataset[\"ADM\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"ADM\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"ADM\" + str(i + 5), \"ADM\" + str(i + 4), \"ADM\" + str(i + 3), \"ADM\" + str(i + 2), \"ADM\" + str(i + 1), \"ADM\" + str(i)]]\n",
    "    train_data.columns = [\"ADM6\", 'age', 'gender', 'BMI', \"temperature5\",\"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"ADM5\", \"ADM4\", \"ADM3\", \"ADM2\", \"ADM1\", \"ADM0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ADM_6days\"] = (dataset[\"ADM\" + str(i + 5)] + dataset[\"ADM\" + str(i + 4)] + dataset[\"ADM\" + str(i + 3)] + dataset[\"ADM\" + str(i + 2)] + dataset[\"ADM\" + str(i + 1)] + dataset[\"ADM\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ADM_3days\"] = (dataset[\"ADM\" + str(i + 5)] + dataset[\"ADM\" + str(i + 4)] + dataset[\"ADM\" + str(i + 3)]) / 3\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0(i):\n",
    "    train_data = dataset[dataset[\"ADM\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"ADM\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"ADM\" + str(i + 5), \"ADM\" + str(i + 4), \"ADM\" + str(i + 3), \"ADM\" + str(i + 2), \"ADM\" + str(i + 1), \"ADM\" + str(i)]]\n",
    "    train_data.columns = [\"ADM6\", 'age', 'gender', 'BMI', \"temperature5\", \"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"ADM5\", \"ADM4\", \"ADM3\", \"ADM2\", \"ADM1\", \"ADM0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ADM_6days\"] = (dataset[\"ADM\" + str(i + 5)] + dataset[\"ADM\" + str(i + 4)] + dataset[\"ADM\" + str(i + 3)] + dataset[\"ADM\" + str(i + 2)] + dataset[\"ADM\" + str(i + 1)] + dataset[\"ADM\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ADM_3days\"] = (dataset[\"ADM\" + str(i + 5)] + dataset[\"ADM\" + str(i + 4)] + dataset[\"ADM\" + str(i + 3)]) / 3\n",
    "    return train_data\n",
    "\n",
    "def build_testdata(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"ADM\" + str(j)] = test_data[\"ADM\" + str(j + 1)]\n",
    "    test_data[\"ADM5\"] = y\n",
    "    test_data[\"ADM6\"] = dataset[\"ADM\" + str(i + 6)]\n",
    "    test_data.loc[:,\"ADM_6days\"] = (test_data[\"ADM0\"] + test_data[\"ADM1\"] + test_data[\"ADM2\"] + test_data[\"ADM3\"] + test_data[\"ADM4\"] + test_data[\"ADM5\"]) / 6\n",
    "    test_data.loc[:,\"ADM_3days\"] = (test_data[\"ADM3\"] + test_data[\"ADM4\"] + test_data[\"ADM5\"]) / 3\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b852d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light gbm\n",
    "\n",
    "mse = []\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mse_list = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'ADM5', 'ADM4', 'ADM3','ADM2', 'ADM1', 'ADM0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'ADM_6days', 'ADM_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # ADM\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # ADM\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # ADM\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # ADM\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list.extend(list(y1))\n",
    "    y_list.extend(list(y2))\n",
    "    y_list.extend(list(y3))\n",
    "    \n",
    "    y_hat_list.extend(list(y1_hat))\n",
    "    y_hat_list.extend(list(y2_hat))\n",
    "    y_hat_list.extend(list(y3_hat))\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    mse_list = mse_list.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7737938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "\n",
    "mse_xgboost = []\n",
    "y_list_xgboost = []\n",
    "y_hat_list_xgboost = []\n",
    "y_list_bi_xgboost = []\n",
    "y_hat_list_bi_xgboost = []\n",
    "y_list_bi_xgboost_3day = []\n",
    "y_hat_list_bi_xgboost_3day = []\n",
    "mse_list_xgboost = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params0 = {\n",
    "            'max_depth': 3,\n",
    "            'n_estimators': 50,\n",
    "            'learning_rate': 0.09\n",
    "}\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'ADM5', 'ADM4', 'ADM3','ADM2', 'ADM1', 'ADM0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'ADM_6days', 'ADM_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # ADM\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    y0 = build_traindata(i).iloc[:,0]\n",
    "    model=xgb.XGBRegressor(**params0)\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # ADM\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # ADM\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # ADM\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    y_list_xgboost.extend(list(y1))\n",
    "    y_list_xgboost.extend(list(y2))\n",
    "    y_list_xgboost.extend(list(y3))\n",
    "    y_hat_list_xgboost.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost.extend(list(y3_hat))\n",
    "    y_list_bi_xgboost.extend(np.array(y0) - np.array(y1) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y1) - np.array(y2) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y2) - np.array(y3) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y0) - np.array(y1_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y1_hat) - np.array(y2_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y2_hat) - np.array(y3_hat) > 0)\n",
    "    y_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1) + np.array(y2) + np.array(y3)) / 3  > 0)\n",
    "    y_hat_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1_hat) + np.array(y2_hat) + np.array(y1_hat)) / 3  > 0)\n",
    "    mse_list_xgboost = mse_list_xgboost.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    mse_xgboost.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9412b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(np.array(y_hat_list_bi_xgboost) == y_list_bi_xgboost) / len(y_list_bi_xgboost))\n",
    "print(sum(np.array(y_hat_list_bi_xgboost_3day) == y_list_bi_xgboost_3day) / len(y_list_bi_xgboost_3day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array([random.choice([True, False]) for i in y_list_bi_xgboost]) == y_list_bi_xgboost) / len(y_list_bi_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584be8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_list_bi_xgboost_3day, y_hat_list_bi_xgboost_3day)\n",
    "TN = int(cm[0][0])\n",
    "FP = int(cm[0][1])\n",
    "FN = int(cm[1][0])\n",
    "TP = int(cm[1][1])\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "precision = TP / (TP+FP)  # \n",
    "recall = TP / (TP+FN)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91112b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_list_bi_xgboost_3day) - sum(y_list_bi_xgboost_3day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1193 / (1737 + 1737)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_list_xgboost,y_hat_list_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean : %s\" % (sum(sum(i) for i in mse_avg_ADM)/sum(len(i) for i in mse_avg_ADM)))\n",
    "print(\"naive : %s\" % (sum(sum(i) for i in mse_naive_ADM)/sum(len(i) for i in mse_naive_ADM)))\n",
    "print(\"ets : %s\" % (sum(sum(i) for i in mse_ets_ADM)/sum(len(i) for i in mse_ets_ADM)))\n",
    "print(\"moving average : %s\" % (sum(sum(i) for i in mse_movingavg_ADM)/sum(len(i) for i in mse_movingavg_ADM)))\n",
    "print(\"arima(1,1,1) : %s\" % (sum(sum(i) for i in mse_arima_ADM)/sum(len(i) for i in mse_arima_ADM)))\n",
    "print(\"arima(0,1,1) : %s\" % (sum(sum(i) for i in mse_arima2_ADM)/sum(len(i) for i in mse_arima2_ADM)))\n",
    "print(\"arima(1,1,0) : %s\" % (sum(sum(i) for i in mse_arima3_ADM)/sum(len(i) for i in mse_arima3_ADM)))\n",
    "print(\"lightgbm : %s\" % (mean_squared_error(y_list,y_hat_list)))\n",
    "print(\"xgboost : %s\" % (mean_squared_error(y_list_xgboost,y_hat_list_xgboost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb236fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model, max_num_features=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13678413",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(m_lgb, max_num_features=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78090f5d",
   "metadata": {},
   "source": [
    "# forecast ETN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c91ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(_y1, _y1_) ** (1/2))\n",
    "print(mean_squared_error(_y2, _y2_) ** (1/2))\n",
    "print(mean_squared_error(_y3, _y3_) ** (1/2))\n",
    "print(mean_squared_error(_y3 + _y2 + _y1, _y3_ + _y2_ + _y1_) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"naive\":[sum(x)/len(x) for x in mse_naive_ETN[:50]]\n",
    "                  ,\"mean\":[sum(x)/len(x) for x in mse_avg_ETN[:50]]\n",
    "                  ,\"exponential smoothing\":[sum(x)/len(x) for x in mse_ets_ETN[:50]]\n",
    "                  ,\"ARIMA(1,1,1)\":[sum(x)/len(x) for x in mse_arima_ETN[:50]]\n",
    "                  ,\"ARIMA(0,1,1)\":[sum(x)/len(x) for x in mse_arima2_ETN[:50]]\n",
    "                  ,\"ARIMA(1,1,0)\":[sum(x)/len(x) for x in mse_arima3_ETN[:50]]\n",
    "                  ,\"Light GBM\": mse[:50]\n",
    "                  ,\"Xgboost\": mse_xgboost[:50]})\n",
    "a.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82288d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# traditional \n",
    "\n",
    "mse_avg_ETN = [[] for i in range(100)]\n",
    "mse_naive_ETN = [[] for i in range(100)]\n",
    "mse_ets_ETN = [[] for i in range(100)]\n",
    "mse_movingavg_ETN = [[] for i in range(100)]\n",
    "mse_arima_ETN = [[] for i in range(100)]\n",
    "mse_arima2_ETN = [[] for i in range(100)]\n",
    "mse_arima3_ETN = [[] for i in range(100)]\n",
    "\n",
    "y1 = []\n",
    "y1_ = []\n",
    "y2 = []\n",
    "y2_ = []\n",
    "y3 = []\n",
    "y3_ = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"ETN\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_ETN[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_ETN[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_ETN[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "        \n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_ETN[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_ETN[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_ETN[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "\n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_ETN[i].append(mean_squared_error(data[-3:], y_hat_8))\n",
    "        \n",
    "        y1.append(data.values[-3])\n",
    "        y1_.append(y_hat_8.values[-3])\n",
    "        y2.append(data.values[-2])\n",
    "        y2_.append(y_hat_8.values[-2])\n",
    "        y3.append(data.values[-1])\n",
    "        y3_.append(y_hat_8.values[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce36a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine learning\n",
    "\n",
    "data = pd.read_csv(\"cleaned_structured_data.csv\", sep = \";\")\n",
    "data = data.set_index([\"id\"])\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"id\"] = data.reset_index()[\"id\"].unique()\n",
    "dataset = dataset.set_index(\"id\")\n",
    "for i in range(107):\n",
    "    dataset[\"ETN\" + str(i)] = data[data[\"day\"] == i][\"ETN\"]\n",
    "    dataset[\"o2Saturation\" + str(i)] = data[data[\"day\"] == i][\"o2Saturation\"]\n",
    "    dataset[\"temperature\" + str(i)] = data[data[\"day\"] == i][\"temperature\"]\n",
    "    dataset[\"bloodPressure\" + str(i)] = data[data[\"day\"] == i][\"bloodPressure\"]\n",
    "    dataset[\"ETN\" + str(i)] = data[data[\"day\"] == i][\"ETN\"]\n",
    "dataset[\"age\"] = data.groupby(\"id\").first()[\"age\"]\n",
    "dataset[\"gender\"] = data.groupby(\"id\").first()[\"gender\"]\n",
    "dataset[\"BMI\"] = data.groupby(\"id\").mean()[\"BMI\"]\n",
    "dataset[\"gender\"] = np.where(dataset[\"gender\"] == \"Man\", 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata(i):\n",
    "    train_data = dataset[dataset[\"ETN\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"ETN\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"ETN\" + str(i + 5), \"ETN\" + str(i + 4), \"ETN\" + str(i + 3), \"ETN\" + str(i + 2), \"ETN\" + str(i + 1), \"ETN\" + str(i)]]\n",
    "    train_data.columns = [\"ETN6\", 'age', 'gender', 'BMI', \"temperature5\",\"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"ETN5\", \"ETN4\", \"ETN3\", \"ETN2\", \"ETN1\", \"ETN0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ETN_6days\"] = (dataset[\"ETN\" + str(i + 5)] + dataset[\"ETN\" + str(i + 4)] + dataset[\"ETN\" + str(i + 3)] + dataset[\"ETN\" + str(i + 2)] + dataset[\"ETN\" + str(i + 1)] + dataset[\"ETN\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ETN_3days\"] = (dataset[\"ETN\" + str(i + 5)] + dataset[\"ETN\" + str(i + 4)] + dataset[\"ETN\" + str(i + 3)]) / 3\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0(i):\n",
    "    train_data = dataset[dataset[\"ETN\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"ETN\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"ETN\" + str(i + 5), \"ETN\" + str(i + 4), \"ETN\" + str(i + 3), \"ETN\" + str(i + 2), \"ETN\" + str(i + 1), \"ETN\" + str(i)]]\n",
    "    train_data.columns = [\"ETN6\", 'age', 'gender', 'BMI', \"temperature5\", \"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"ETN5\", \"ETN4\", \"ETN3\", \"ETN2\", \"ETN1\", \"ETN0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ETN_6days\"] = (dataset[\"ETN\" + str(i + 5)] + dataset[\"ETN\" + str(i + 4)] + dataset[\"ETN\" + str(i + 3)] + dataset[\"ETN\" + str(i + 2)] + dataset[\"ETN\" + str(i + 1)] + dataset[\"ETN\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"ETN_3days\"] = (dataset[\"ETN\" + str(i + 5)] + dataset[\"ETN\" + str(i + 4)] + dataset[\"ETN\" + str(i + 3)]) / 3\n",
    "    return train_data\n",
    "\n",
    "def build_testdata(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"ETN\" + str(j)] = test_data[\"ETN\" + str(j + 1)]\n",
    "    test_data[\"ETN5\"] = y\n",
    "    test_data[\"ETN6\"] = dataset[\"ETN\" + str(i + 6)]\n",
    "    test_data.loc[:,\"ETN_6days\"] = (test_data[\"ETN0\"] + test_data[\"ETN1\"] + test_data[\"ETN2\"] + test_data[\"ETN3\"] + test_data[\"ETN4\"] + test_data[\"ETN5\"]) / 6\n",
    "    test_data.loc[:,\"ETN_3days\"] = (test_data[\"ETN3\"] + test_data[\"ETN4\"] + test_data[\"ETN5\"]) / 3\n",
    "\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a74697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light gbm\n",
    "\n",
    "mse = []\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mse_list = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'ETN5', 'ETN4', 'ETN3','ETN2', 'ETN1', 'ETN0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'ETN_6days', 'ETN_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # ETN\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # ETN\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # ETN\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # ETN\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list.extend(list(y1))\n",
    "    y_list.extend(list(y2))\n",
    "    y_list.extend(list(y3))\n",
    "    \n",
    "    y_hat_list.extend(list(y1_hat))\n",
    "    y_hat_list.extend(list(y2_hat))\n",
    "    y_hat_list.extend(list(y3_hat))\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    \n",
    "    mse_list = mse_list.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "\n",
    "mse_xgboost = []\n",
    "y_list_xgboost = []\n",
    "y_hat_list_xgboost = []\n",
    "y_list_bi_xgboost = []\n",
    "y_hat_list_bi_xgboost = []\n",
    "y_list_bi_xgboost_3day = []\n",
    "y_hat_list_bi_xgboost_3day = []\n",
    "mse_list_xgboost = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params0 = {\n",
    "            'max_depth': 3,\n",
    "            'n_estimators': 50,\n",
    "            'learning_rate': 0.09\n",
    "}\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'ETN5', 'ETN4', 'ETN3','ETN2', 'ETN1', 'ETN0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'ETN_6days', 'ETN_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # ETN\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    y0 = build_traindata(i).iloc[:,0]\n",
    "    model=xgb.XGBRegressor(**params0)\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # ETN\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # ETN\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # ETN\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    y_list_xgboost.extend(list(y1))\n",
    "    y_list_xgboost.extend(list(y2))\n",
    "    y_list_xgboost.extend(list(y3))\n",
    "    y_hat_list_xgboost.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost.extend(list(y3_hat))\n",
    "    y_list_bi_xgboost.extend(np.array(y0) - np.array(y1) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y1) - np.array(y2) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y2) - np.array(y3) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y0) - np.array(y1_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y1_hat) - np.array(y2_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y2_hat) - np.array(y3_hat) > 0)\n",
    "    y_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1) + np.array(y2) + np.array(y3)) / 3  > 0)\n",
    "    y_hat_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1_hat) + np.array(y2_hat) + np.array(y1_hat)) / 3  > 0)\n",
    "    mse_list_xgboost = mse_list_xgboost.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    mse_xgboost.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de623f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean : %s\" % (sum(sum(i) for i in mse_avg_ETN)/sum(len(i) for i in mse_avg_ETN)))\n",
    "print(\"naive : %s\" % (sum(sum(i) for i in mse_naive_ETN)/sum(len(i) for i in mse_naive_ETN)))\n",
    "print(\"ets : %s\" % (sum(sum(i) for i in mse_ets_ETN)/sum(len(i) for i in mse_ets_ETN)))\n",
    "print(\"moving average : %s\" % (sum(sum(i) for i in mse_movingavg_ETN)/sum(len(i) for i in mse_movingavg_ETN)))\n",
    "print(\"arima(1,1,1) : %s\" % (sum(sum(i) for i in mse_arima_ETN)/sum(len(i) for i in mse_arima_ETN)))\n",
    "print(\"arima(0,1,1) : %s\" % (sum(sum(i) for i in mse_arima2_ETN)/sum(len(i) for i in mse_arima2_ETN)))\n",
    "print(\"arima(1,1,0) : %s\" % (sum(sum(i) for i in mse_arima3_ETN)/sum(len(i) for i in mse_arima3_ETN)))\n",
    "print(\"lightgbm : %s\" % (mean_squared_error(y_list,y_hat_list)))\n",
    "print(\"xgboost : %s\" % (mean_squared_error(y_list_xgboost,y_hat_list_xgboost)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(np.array(y_hat_list_bi_xgboost) == y_list_bi_xgboost) / len(y_list_bi_xgboost))\n",
    "print(sum(np.array(y_hat_list_bi_xgboost_3day) == y_list_bi_xgboost_3day) / len(y_list_bi_xgboost_3day))\n",
    "print(sum(np.array([random.choice([True, False]) for i in y_list_bi_xgboost]) == y_list_bi_xgboost) / len(y_list_bi_xgboost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b80c03",
   "metadata": {},
   "source": [
    "# forecast STM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab686b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(_y1, _y1_) ** (1/2))\n",
    "print(mean_squared_error(_y2, _y2_) ** (1/2))\n",
    "print(mean_squared_error(_y3, _y3_) ** (1/2))\n",
    "print(mean_squared_error(_y3 + _y2 + _y1, _y3_ + _y2_ + _y1_) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ac01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_naive_STM[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99745271",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"naive\":[sum(x)/len(x) for x in mse_naive_STM[:50]]\n",
    "                  ,\"mean\":[sum(x)/len(x) for x in mse_avg_STM[:50]]\n",
    "                  ,\"exponential smoothing\":[sum(x)/len(x) for x in mse_ets_STM[:50]]\n",
    "                  ,\"ARIMA(1,1,1)\":[sum(x)/len(x) for x in mse_arima_STM[:50]]\n",
    "                  ,\"ARIMA(0,1,1)\":[sum(x)/len(x) for x in mse_arima2_STM[:50]]\n",
    "                  ,\"ARIMA(1,1,0)\":[sum(x)/len(x) for x in mse_arima3_STM[:50]]\n",
    "                  ,\"Light GBM\": mse[:50]\n",
    "                  ,\"Xgboost\": mse_xgboost[:50]})\n",
    "a.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional \n",
    "\n",
    "mse_avg_STM = [[] for i in range(100)]\n",
    "mse_naive_STM = [[] for i in range(100)]\n",
    "mse_ets_STM = [[] for i in range(100)]\n",
    "mse_movingavg_STM = [[] for i in range(100)]\n",
    "mse_arima_STM = [[] for i in range(100)]\n",
    "mse_arima2_STM = [[] for i in range(100)]\n",
    "mse_arima3_STM = [[] for i in range(100)]\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "for i in range(100):\n",
    "    for series in time_series_set[i]:\n",
    "        \n",
    "        data = series[\"STM\"]\n",
    "\n",
    "        # average\n",
    "        y_hat_1 = [sum(data[:-3])/len(data[:-3])] * 3\n",
    "        mse_avg_STM[i].append(mean_squared_error(data[-3:], y_hat_1))\n",
    "\n",
    "        # naive\n",
    "        model_2 = ExponentialSmoothing(data[:-3])\n",
    "        model_fit_2 = model_2.fit()\n",
    "        y_hat_2 = model_fit_2.predict(len(data)-3, len(data)-1) \n",
    "        mse_naive_STM[i].append(mean_squared_error(data[-3:], y_hat_2))\n",
    "\n",
    "        # ets\n",
    "        model_3 = ExponentialSmoothing(data[:-3], trend=\"add\")\n",
    "        model_fit_3 = model_3.fit()\n",
    "        y_hat_3 = model_fit_3.predict(len(data)-3, len(data)-1)\n",
    "        mse_ets_STM[i].append(mean_squared_error(data[-3:], y_hat_3))\n",
    "\n",
    "        # moving average\n",
    "        model_5 = ARIMA(data[:-3], order=(0, 0, 1))\n",
    "        model_fit_5 = model_5.fit()\n",
    "        y_hat_5 = model_fit_5.predict(len(data)-3, len(data)-1)\n",
    "        mse_movingavg_STM[i].append(mean_squared_error(data[-3:], y_hat_5))\n",
    "\n",
    "        model_6 = ARIMA(data[:-3], order=(1, 1, 1))\n",
    "        model_fit_6 = model_6.fit()\n",
    "        y_hat_6 = model_fit_6.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima_STM[i].append(mean_squared_error(data[-3:], y_hat_6))\n",
    "\n",
    "        model_7 = ARIMA(data[:-3], order=(0, 1, 1))\n",
    "        model_fit_7 = model_7.fit()\n",
    "        y_hat_7 = model_fit_7.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima2_STM[i].append(mean_squared_error(data[-3:], y_hat_7))\n",
    "        \n",
    "        model_8 = ARIMA(data[:-3], order=(1, 1, 0))\n",
    "        model_fit_8 = model_8.fit()\n",
    "        y_hat_8 = model_fit_8.predict(len(data)-3, len(data)-1)\n",
    "        mse_arima3_STM[i].append(mean_squared_error(data[-3:], y_hat_8))\n",
    "\n",
    "        _y1.append(data.values[-3])\n",
    "        _y1_.append(y_hat_8.values[-3])\n",
    "        _y2.append(data.values[-2])\n",
    "        _y2_.append(y_hat_8.values[-2])\n",
    "        _y3.append(data.values[-1])\n",
    "        _y3_.append(y_hat_8.values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine learning\n",
    "\n",
    "data = pd.read_csv(\"cleaned_structured_data.csv\", sep = \";\")\n",
    "data = data.set_index([\"id\"])\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"id\"] = data.reset_index()[\"id\"].unique()\n",
    "dataset = dataset.set_index(\"id\")\n",
    "for i in range(107):\n",
    "    dataset[\"STM\" + str(i)] = data[data[\"day\"] == i][\"STM\"]\n",
    "    dataset[\"o2Saturation\" + str(i)] = data[data[\"day\"] == i][\"o2Saturation\"]\n",
    "    dataset[\"temperature\" + str(i)] = data[data[\"day\"] == i][\"temperature\"]\n",
    "    dataset[\"bloodPressure\" + str(i)] = data[data[\"day\"] == i][\"bloodPressure\"]\n",
    "    dataset[\"STM\" + str(i)] = data[data[\"day\"] == i][\"STM\"]\n",
    "dataset[\"age\"] = data.groupby(\"id\").first()[\"age\"]\n",
    "dataset[\"gender\"] = data.groupby(\"id\").first()[\"gender\"]\n",
    "dataset[\"BMI\"] = data.groupby(\"id\").mean()[\"BMI\"]\n",
    "dataset[\"gender\"] = np.where(dataset[\"gender\"] == \"Man\", 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_traindata(i):\n",
    "    train_data = dataset[dataset[\"STM\" + str(i + 9)].notna()]\n",
    "    train_data = train_data[[\"STM\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"STM\" + str(i + 5), \"STM\" + str(i + 4), \"STM\" + str(i + 3), \"STM\" + str(i + 2), \"STM\" + str(i + 1), \"STM\" + str(i)]]\n",
    "    train_data.columns = [\"STM6\", 'age', 'gender', 'BMI', \"temperature5\",\"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"STM5\", \"STM4\", \"STM3\", \"STM2\", \"STM1\", \"STM0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"STM_6days\"] = (dataset[\"STM\" + str(i + 5)] + dataset[\"STM\" + str(i + 4)] + dataset[\"STM\" + str(i + 3)] + dataset[\"STM\" + str(i + 2)] + dataset[\"STM\" + str(i + 1)] + dataset[\"STM\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"STM_3days\"] = (dataset[\"STM\" + str(i + 5)] + dataset[\"STM\" + str(i + 4)] + dataset[\"STM\" + str(i + 3)]) / 3\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def build_testdata0(i):\n",
    "    train_data = dataset[dataset[\"STM\" + str(i + 8)].notna()]\n",
    "    train_data = train_data[[\"STM\" + str(i + 6), 'age', 'gender', 'BMI', \"temperature\" + str(i + 5), \"temperature\" + str(i + 4), \"bloodPressure\" + str(i + 5), \"o2Saturation\" + str(i + 5), \"STM\" + str(i + 5), \"STM\" + str(i + 4), \"STM\" + str(i + 3), \"STM\" + str(i + 2), \"STM\" + str(i + 1), \"STM\" + str(i)]]\n",
    "    train_data.columns = [\"STM6\", 'age', 'gender', 'BMI', \"temperature5\", \"temperature4\", \"bloodPressure5\", \"o2Saturation5\", \"STM5\", \"STM4\", \"STM3\", \"STM2\", \"STM1\", \"STM0\"]\n",
    "    train_data.loc[:,\"temperature_3days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"temperature_6days\"] = (dataset[\"temperature\" + str(i + 5)] + dataset[\"temperature\" + str(i + 4)] + dataset[\"temperature\" + str(i + 3)] + dataset[\"temperature\" + str(i + 2)] + dataset[\"temperature\" + str(i + 1)] + dataset[\"temperature\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"bloodPressure_3days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"bloodPressure_6days\"] = (dataset[\"bloodPressure\" + str(i + 5)] + dataset[\"bloodPressure\" + str(i + 4)] + dataset[\"bloodPressure\" + str(i + 3)] + dataset[\"bloodPressure\" + str(i + 2)] + dataset[\"bloodPressure\" + str(i + 1)] + dataset[\"bloodPressure\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"o2Saturation_3days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)]) / 3\n",
    "    train_data.loc[:,\"o2Saturation_6days\"] = (dataset[\"o2Saturation\" + str(i + 5)] + dataset[\"o2Saturation\" + str(i + 4)] + dataset[\"o2Saturation\" + str(i + 3)] + dataset[\"o2Saturation\" + str(i + 2)] + dataset[\"o2Saturation\" + str(i + 1)] + dataset[\"o2Saturation\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"STM_6days\"] = (dataset[\"STM\" + str(i + 5)] + dataset[\"STM\" + str(i + 4)] + dataset[\"STM\" + str(i + 3)] + dataset[\"STM\" + str(i + 2)] + dataset[\"STM\" + str(i + 1)] + dataset[\"STM\" + str(i)]) / 6\n",
    "    train_data.loc[:,\"STM_3days\"] = (dataset[\"STM\" + str(i + 5)] + dataset[\"STM\" + str(i + 4)] + dataset[\"STM\" + str(i + 3)]) / 3\n",
    "    return train_data\n",
    "\n",
    "def build_testdata(train_data, y, i):\n",
    "    test_data = train_data[train_data.columns]\n",
    "    for j in range(5):\n",
    "        test_data[\"STM\" + str(j)] = test_data[\"STM\" + str(j + 1)]\n",
    "    test_data[\"STM5\"] = y\n",
    "    test_data[\"STM6\"] = dataset[\"STM\" + str(i + 6)]\n",
    "    test_data.loc[:,\"STM_6days\"] = (test_data[\"STM0\"] + test_data[\"STM1\"] + test_data[\"STM2\"] + test_data[\"STM3\"] + test_data[\"STM4\"] + test_data[\"STM5\"]) / 6\n",
    "    test_data.loc[:,\"STM_3days\"] = (test_data[\"STM3\"] + test_data[\"STM4\"] + test_data[\"STM5\"]) / 3\n",
    "\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d81f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_traindata(0).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2333dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light gbm\n",
    "\n",
    "mse = []\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mse_list = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'STM5', 'STM4', 'STM3','STM2', 'STM1', 'STM0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'STM_6days', 'STM_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # STM\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    trainData = lgb.Dataset(data=x,label=y)\n",
    "    m_lgb = lgb.train(params, trainData) \n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # STM\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = m_lgb.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # STM\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = m_lgb.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # STM\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = m_lgb.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    y_list.extend(list(y1))\n",
    "    y_list.extend(list(y2))\n",
    "    y_list.extend(list(y3))\n",
    "    \n",
    "    y_hat_list.extend(list(y1_hat))\n",
    "    y_hat_list.extend(list(y2_hat))\n",
    "    y_hat_list.extend(list(y3_hat))\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    \n",
    "    mse_list = mse_list.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    \n",
    "    mse.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "\n",
    "mse_xgboost = []\n",
    "y_list_xgboost = []\n",
    "y_hat_list_xgboost = []\n",
    "y_list_bi_xgboost = []\n",
    "y_hat_list_bi_xgboost = []\n",
    "y_list_bi_xgboost_3day = []\n",
    "y_hat_list_bi_xgboost_3day = []\n",
    "mse_list_xgboost = pd.Series()\n",
    "train_data = pd.DataFrame()\n",
    "train_data_temperature = pd.DataFrame()\n",
    "train_data_bloodPressure = pd.DataFrame()\n",
    "train_data_o2Saturation = pd.DataFrame()\n",
    "\n",
    "_y1 = []\n",
    "_y1_ = []\n",
    "_y2 = []\n",
    "_y2_ = []\n",
    "_y3 = []\n",
    "_y3_ = []\n",
    "\n",
    "params0 = {\n",
    "            'max_depth': 3,\n",
    "            'n_estimators': 50,\n",
    "            'learning_rate': 0.09\n",
    "}\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"regression\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.015,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"metric\": [\"mse\"],\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 100,\n",
    "          'min_child_samples': 30,\n",
    "          'min_child_weight': 0.001,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 2\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "            'max_depth': 2,\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "cols = ['age', 'gender', 'BMI', 'temperature5', 'bloodPressure5','o2Saturation5', 'STM5', 'STM4', 'STM3','STM2', 'STM1', 'STM0', 'temperature_3days', 'temperature_6days', 'bloodPressure_3days', 'bloodPressure_6days', 'o2Saturation_3days', 'o2Saturation_6days', 'STM_6days', 'STM_3days']\n",
    "\n",
    "for i in range(97):\n",
    "    # train model\n",
    "    # temperature\n",
    "    train_data_temperature = train_data_temperature.append(build_traindata_temperature(i))\n",
    "    x_temperature = train_data_temperature.iloc[:,1:]\n",
    "    y_temperature = train_data_temperature.iloc[:,0]\n",
    "    trainData_temperature = lgb.Dataset(data=x_temperature,label=y_temperature)\n",
    "    m_lgb_temperature = lgb.train(params, trainData_temperature)\n",
    "    # bloodPressure\n",
    "    train_data_bloodPressure = train_data_bloodPressure.append(build_traindata_bloodPressure(i))\n",
    "    x_bloodPressure = train_data_bloodPressure.iloc[:,1:]\n",
    "    y_bloodPressure = train_data_bloodPressure.iloc[:,0]\n",
    "    trainData_bloodPressure = lgb.Dataset(data=x_bloodPressure,label=y_bloodPressure)\n",
    "    m_lgb_bloodPressure = lgb.train(params, trainData_bloodPressure)\n",
    "    #o2Saturation\n",
    "    train_data_o2Saturation = train_data_o2Saturation.append(build_traindata_o2Saturation(i))\n",
    "    x_o2Saturation = train_data_o2Saturation.iloc[:,1:]\n",
    "    y_o2Saturation = train_data_o2Saturation.iloc[:,0]\n",
    "    model_o2Saturation=xgb.XGBRegressor(**params_xgboost)\n",
    "    model_o2Saturation.fit(x_o2Saturation, y_o2Saturation)\n",
    "    # STM\n",
    "    train_data = train_data.append(build_traindata(i))\n",
    "    x = train_data.iloc[:,1:][cols]\n",
    "    y = train_data.iloc[:,0]\n",
    "    y0 = build_traindata(i).iloc[:,0]\n",
    "    model=xgb.XGBRegressor(**params0)\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # forecast day1\n",
    "    # temperature\n",
    "    test_data1_temperature = build_testdata0_temperature(i+1)\n",
    "    x1_temperature = test_data1_temperature.iloc[:,1:]\n",
    "    y1_temperature = test_data1_temperature.iloc[:,0]\n",
    "    y1_hat_temperature = m_lgb_temperature.predict(x1_temperature)\n",
    "    x1_temperature[\"pred\"] = y1_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data1_bloodPressure = build_testdata0_bloodPressure(i+1)\n",
    "    x1_bloodPressure = test_data1_bloodPressure.iloc[:,1:]\n",
    "    y1_bloodPressure = test_data1_bloodPressure.iloc[:,0]\n",
    "    y1_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure)\n",
    "    x1_bloodPressure[\"pred\"] = y1_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data1_o2Saturation = build_testdata0_o2Saturation(i+1)\n",
    "    x1_o2Saturation = test_data1_o2Saturation.iloc[:,1:]\n",
    "    y1_o2Saturation = test_data1_o2Saturation.iloc[:,0]\n",
    "    y1_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation)\n",
    "    x1_o2Saturation[\"pred\"] = y1_hat_o2Saturation\n",
    "    # STM\n",
    "    test_data1 = build_testdata0(i+1)\n",
    "    x1 = test_data1.iloc[:,1:][cols]\n",
    "    y1 = test_data1.iloc[:,0]\n",
    "    y1_hat = model.predict(x1)\n",
    "    x1[\"pred\"] = y1_hat\n",
    "    \n",
    "    # forecast day2\n",
    "    # temperature\n",
    "    test_data2_temperature = build_testdata_temperature(test_data1_temperature, y1_hat_temperature, i+2)\n",
    "    x2_temperature = test_data2_temperature.iloc[:,1:]\n",
    "    y2_temperature = test_data2_temperature.iloc[:,0]\n",
    "    y2_hat_temperature = m_lgb_temperature.predict(x1_temperature.iloc[:, :-1])\n",
    "    x2_temperature[\"pred\"] = y2_hat_temperature\n",
    "    # bloodPressure\n",
    "    test_data2_bloodPressure = build_testdata_bloodPressure(test_data1_bloodPressure, y1_hat_bloodPressure, i+2)\n",
    "    x2_bloodPressure = test_data2_bloodPressure.iloc[:,1:]\n",
    "    y2_bloodPressure = test_data2_bloodPressure.iloc[:,0]\n",
    "    y2_hat_bloodPressure = m_lgb_bloodPressure.predict(x1_bloodPressure.iloc[:, :-1])\n",
    "    x2_bloodPressure[\"pred\"] = y2_hat_bloodPressure\n",
    "    # o2Saturation\n",
    "    test_data2_o2Saturation = build_testdata_o2Saturation(test_data1_o2Saturation, y1_hat_o2Saturation, i+2)\n",
    "    x2_o2Saturation = test_data2_o2Saturation.iloc[:,1:]\n",
    "    y2_o2Saturation = test_data2_o2Saturation.iloc[:,0]\n",
    "    y2_hat_o2Saturation = model_o2Saturation.predict(x1_o2Saturation.iloc[:, :-1])\n",
    "    x2_o2Saturation[\"pred\"] = y2_hat_o2Saturation\n",
    "    # STM\n",
    "    test_data2 = build_testdata(test_data1, y1_hat, i+2)\n",
    "    test_data2[\"temperature5\"] = x1_temperature[\"pred\"]\n",
    "    test_data2[\"temperature_3days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"]) / 3\n",
    "    test_data2[\"temperature_6days\"] = (x1_temperature[\"pred\"] + x1_temperature[\"temperature5\"] + x1_temperature[\"temperature4\"] + x1_temperature[\"temperature3\"] + x1_temperature[\"temperature2\"] + x1_temperature[\"temperature1\"]) / 6\n",
    "    test_data2[\"bloodPressure5\"] = x1_bloodPressure[\"pred\"]\n",
    "    test_data2[\"bloodPressure_3days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data2[\"bloodPressure_6days\"] = (x1_bloodPressure[\"pred\"] + x1_bloodPressure[\"bloodPressure5\"] + x1_bloodPressure[\"bloodPressure4\"] + x1_bloodPressure[\"bloodPressure3\"] + x1_bloodPressure[\"bloodPressure2\"] + x1_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data2[\"o2Saturation5\"] = x1_o2Saturation[\"pred\"]\n",
    "    test_data2[\"o2Saturation_3days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data2[\"o2Saturation_6days\"] = (x1_o2Saturation[\"pred\"] + x1_o2Saturation[\"o2Saturation5\"] + x1_o2Saturation[\"o2Saturation4\"] + x1_o2Saturation[\"o2Saturation3\"] + x1_o2Saturation[\"o2Saturation2\"] + x1_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x2 = test_data2.iloc[:,1:][cols]\n",
    "    y2 = test_data2.iloc[:,0]\n",
    "    y2_hat = model.predict(x2)\n",
    "    x2[\"pred\"] = y2_hat\n",
    "    \n",
    "    # forecast day3\n",
    "    # STM\n",
    "    test_data3 = build_testdata(test_data2, y2_hat, i+2)\n",
    "    test_data3[\"temperature5\"] = x2_temperature[\"pred\"]\n",
    "    test_data3[\"temperature_3days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"]) / 3\n",
    "    test_data3[\"temperature_6days\"] = (x2_temperature[\"pred\"] + x2_temperature[\"temperature5\"] + x2_temperature[\"temperature4\"] + x2_temperature[\"temperature3\"] + x2_temperature[\"temperature2\"] + x2_temperature[\"temperature1\"]) / 6\n",
    "    test_data3[\"bloodPressure5\"] = x2_bloodPressure[\"pred\"]\n",
    "    test_data3[\"bloodPressure_3days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"]) / 3\n",
    "    test_data3[\"bloodPressure_6days\"] = (x2_bloodPressure[\"pred\"] + x2_bloodPressure[\"bloodPressure5\"] + x2_bloodPressure[\"bloodPressure4\"] + x2_bloodPressure[\"bloodPressure3\"] + x2_bloodPressure[\"bloodPressure2\"] + x2_bloodPressure[\"bloodPressure1\"]) / 6\n",
    "    test_data3[\"o2Saturation5\"] = x2_o2Saturation[\"pred\"]\n",
    "    test_data3[\"o2Saturation_3days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"]) / 3\n",
    "    test_data3[\"o2Saturation_6days\"] = (x2_o2Saturation[\"pred\"] + x2_o2Saturation[\"o2Saturation5\"] + x2_o2Saturation[\"o2Saturation4\"] + x2_o2Saturation[\"o2Saturation3\"] + x2_o2Saturation[\"o2Saturation2\"] + x2_o2Saturation[\"o2Saturation1\"]) / 6\n",
    "    x3 = test_data3.iloc[:,1:][cols]\n",
    "    y3 = test_data3.iloc[:,0]\n",
    "    y3_hat = model.predict(x3)\n",
    "    x3[\"pred\"] = y3_hat\n",
    "    \n",
    "    _y1 += (list(y1))\n",
    "    _y2 += (list(y2))\n",
    "    _y3 += (list(y3))\n",
    "    \n",
    "    _y1_ += (list(y1_hat))\n",
    "    _y2_ += (list(y2_hat))\n",
    "    _y3_ += (list(y3_hat))\n",
    "    \n",
    "    y_list_xgboost.extend(list(y1))\n",
    "    y_list_xgboost.extend(list(y2))\n",
    "    y_list_xgboost.extend(list(y3))\n",
    "    y_hat_list_xgboost.extend(list(y1_hat))\n",
    "    y_hat_list_xgboost.extend(list(y2_hat))\n",
    "    y_hat_list_xgboost.extend(list(y3_hat))\n",
    "    y_list_bi_xgboost.extend(np.array(y0) - np.array(y1) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y1) - np.array(y2) > 0)\n",
    "    y_list_bi_xgboost.extend(np.array(y2) - np.array(y3) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y0) - np.array(y1_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y1_hat) - np.array(y2_hat) > 0)\n",
    "    y_hat_list_bi_xgboost.extend(np.array(y2_hat) - np.array(y3_hat) > 0)\n",
    "    y_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1) + np.array(y2) + np.array(y3)) / 3  > 0)\n",
    "    y_hat_list_bi_xgboost_3day.extend(np.array(y0) - (np.array(y1_hat) + np.array(y2_hat) + np.array(y1_hat)) / 3  > 0)\n",
    "    mse_list_xgboost = mse_list_xgboost.append((y1 - x1[\"pred\"]) ** 2).append((y2 - x2[\"pred\"]) ** 2).append((y3 - x3[\"pred\"]) ** 2)\n",
    "    mse_xgboost.append((mean_squared_error(y1,y1_hat) * len(test_data1) + mean_squared_error(y2,y2_hat) * len(test_data2) + mean_squared_error(y3,y3_hat) * len(test_data3)) / (len(test_data1) + len(test_data2) + len(test_data3)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean : %s\" % (sum(sum(i) for i in mse_avg_STM)/sum(len(i) for i in mse_avg_STM)))\n",
    "print(\"naive : %s\" % (sum(sum(i) for i in mse_naive_STM)/sum(len(i) for i in mse_naive_STM)))\n",
    "print(\"ets : %s\" % (sum(sum(i) for i in mse_ets_STM)/sum(len(i) for i in mse_ets_STM)))\n",
    "print(\"moving average : %s\" % (sum(sum(i) for i in mse_movingavg_STM)/sum(len(i) for i in mse_movingavg_STM)))\n",
    "print(\"arima(1,1,1) : %s\" % (sum(sum(i) for i in mse_arima_STM)/sum(len(i) for i in mse_arima_STM)))\n",
    "print(\"arima(0,1,1) : %s\" % (sum(sum(i) for i in mse_arima2_STM)/sum(len(i) for i in mse_arima2_STM)))\n",
    "print(\"arima(1,1,0) : %s\" % (sum(sum(i) for i in mse_arima3_STM)/sum(len(i) for i in mse_arima3_STM)))\n",
    "print(\"lightgbm : %s\" % (mean_squared_error(y_list,y_hat_list)))\n",
    "print(\"xgboost : %s\" % (mean_squared_error(y_list_xgboost,y_hat_list_xgboost)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef06f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(np.array(y_hat_list_bi_xgboost) == y_list_bi_xgboost) / len(y_list_bi_xgboost))\n",
    "print(sum(np.array(y_hat_list_bi_xgboost_3day) == y_list_bi_xgboost_3day) / len(y_list_bi_xgboost_3day))\n",
    "print(sum(np.array([random.choice([True, False]) for i in y_list_bi_xgboost]) == y_list_bi_xgboost) / len(y_list_bi_xgboost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
